{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Generate QM9/ZINC dataset for PyTorch and DGL\n",
    "\n",
    "### Xavier Bresson <br>\n",
    "\n",
    "**Smile datasets**: Molecule is represented with smile/RDKit. The files are in folder QM9_smile/train_smile.txt, val_smile.txt, test_smile.txt <br>\n",
    "**PyTorch datasets**: Molecule is represented with PyTorch. The files are in folder QM9_pytorch/train_pytorch.pkl, val_pytorch.pkl, test_pytorch.pkl, atom_dict.pkl, bond_dict.pkl <br>\n",
    "**DGL datasets**: Molecule is represented with DGL. The files are in folder QM9_dgl/train_dgl.pkl, val_dgl.pkl, test_dgl.pkl <br>\n",
    "\n",
    "**PyTorch molecule structure**: A molecule object (our own class) that contains the following attributes:  \n",
    "◦ molecule[idx].num_atom : nb of atoms, an integer (N)  \n",
    "◦ molecule[idx].atom_type : pytorch tensor of size N, each element is an atom type, an integer between 0 and num_atom_type-1  \n",
    "◦ molecule[idx].atom_type_pe : pytorch tensor of size N, each element is an atom type positional encoding, an integer between 0 and num_atom-1  \n",
    "◦ molecule[idx].bond_type : pytorch tensor of size N x N, each element is a bond type, an integer between 0 and num_bond_type-1  \n",
    "◦ molecule[idx].bag_of_atoms : pytorch tensor of size num_atom_type, histogram of atoms in the molecule  \n",
    "◦ molecule[idx].logP_SA_cycle_normalized : the chemical property to regress, a pytorch float variable  \n",
    "◦ molecule[idx].smile : the smile representation of the molecule for rdkit, a string   \n",
    "◦ idx, an integer between 0 and num_molecules-1 representing the molecule index in the datasets  \n",
    "\n",
    "**DGL molecule structure**: A DGL structure that contains the following members:   \n",
    "◦ molecule[idx] : a tuple (dgl_graph, label) where label is logP_SA_cycle_normalized  \n",
    "◦ dgl_graph : a DGL object that contains  \n",
    "&nbsp; • sparse adjacency matrix  \n",
    "&nbsp; • the node feature with dgl_graph.ndata['feat'] (atom_type)  \n",
    "&nbsp; • the edge feature with dgl_graph.edata['feat'] (bond_type)    \n",
    "\n",
    "\n",
    "**QM9 statistics** <br>\n",
    "test set size : 5,000 <br>\n",
    "val set size : 10,000 <br>\n",
    "train set size : 118,879 <br>\n",
    "min/max molecule size : 4/9<br>\n",
    "\n",
    "**ZINC statistics** <br>\n",
    "test set size :    5,000 <br>\n",
    "val set size :    24,445 <br>\n",
    "train set size : 220,011 <br>\n",
    "min/max molecule size : 6/38 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/GML2023_codes/codes/08_Datasets'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    !pip install dgl=1.0.0 # Install DGL\n",
    "    !pip install rdkit==2023.09.6 # Install RDKit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdmolops\n",
    "from utils_mol import sascorer\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import dgl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions to process smile and generate pytorch molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent of having or not aromaticity\n",
    "def clean_qm9_smiles(list_of_smiles):\n",
    "    new_list_of_smiles = []\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        # remove brakets and CH2\n",
    "        smile = smile.replace('[C]', 'C')\n",
    "        smile = smile.replace('[N]', 'N')\n",
    "        smile = smile.replace('[O]', 'O')\n",
    "        smile = smile.replace('[CH]', 'C')\n",
    "        smile = smile.replace('[NH]', 'N')\n",
    "        smile = smile.replace('[CH2]', 'C')\n",
    "        # remove smile with non-connected compounds\n",
    "        #if '.' in smile:\n",
    "        #    continue\n",
    "        # remove non-connected compounds in smiles \n",
    "        smile = sorted(smile.split('.'), key=len, reverse=True)[0]\n",
    "        new_list_of_smiles.append(smile)\n",
    "    return new_list_of_smiles\n",
    "\n",
    "# independent of having or not aromaticity\n",
    "def remove_stereo_smiles(list_of_smiles):\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        smile = smile.replace('\\\\' , \"\")\n",
    "        smile = smile.replace(\"/\", \"\") \n",
    "        list_of_smiles[idx] = smile\n",
    "    return list_of_smiles\n",
    "\n",
    "def from_smile_to_rdkit_smile(smile):\n",
    "    mol = Chem.MolFromSmiles(smile) # from arbitrary smile to mol\n",
    "    smile = Chem.MolToSmiles(mol) # from mol to rdkit smile\n",
    "    return smile\n",
    "\n",
    "# remove aromatic bonds (smiles are changed)\n",
    "def remove_aromatic_bonds(list_of_smiles):\n",
    "    for idx,smile in enumerate(list_of_smiles): \n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "        smile = Chem.MolToSmiles(mol)\n",
    "        list_of_smiles[idx] = smile\n",
    "    return list_of_smiles\n",
    "\n",
    "def atom2symbol(rdkit_atom):\n",
    "    symbol = rdkit_atom.GetSymbol()\n",
    "    num_explicit_h = rdkit_atom.GetNumExplicitHs()\n",
    "    num_charges = rdkit_atom.GetFormalCharge()\n",
    "    if num_explicit_h!=0:\n",
    "        symbol = symbol + ' H' + str(num_explicit_h)\n",
    "    if num_charges==1:\n",
    "        symbol = symbol + ' +'\n",
    "    if num_charges==-1:\n",
    "        symbol = symbol + ' -'\n",
    "    if abs(num_charges) > 1:\n",
    "        'ERROR!: more than one charge'\n",
    "    return symbol\n",
    "\n",
    "# class of atom and bond dictionaries\n",
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    word2idx and idx2word are mappings from words to idx and vice versa\n",
    "    word2idx is a dictionary\n",
    "    idx2word is a list\n",
    "    word2num_occurence compute the number of times a given word has been added to the dictionary\n",
    "    idx2num_occurence do the same, but with the index of the word rather than the word itself.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.word2num_occurence = {}\n",
    "        self.idx2num_occurence = []\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            # dictionaries\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "            # stats\n",
    "            self.idx2num_occurence.append(0)\n",
    "            self.word2num_occurence[word] = 0\n",
    "        # increase counters    \n",
    "        self.word2num_occurence[word]+=1\n",
    "        self.idx2num_occurence[  self.word2idx[word]  ] += 1\n",
    "    def get_rid_of_rare_words(self, min_num_occurence):\n",
    "        new_idx2word = [ word for word in self.idx2word if self.word2num_occurence[word] >= min_num_occurence  ]\n",
    "        new_word2idx = { word: idx  for idx,word in enumerate(new_idx2word) }         \n",
    "        new_idx2num_occurence = [ self.word2num_occurence[word] for word in new_idx2word]   \n",
    "        new_word2num_occurence = { word: self.word2num_occurence[word]  for word in new_idx2word } \n",
    "        self.word2idx = new_word2idx\n",
    "        self.idx2word = new_idx2word\n",
    "        self.word2num_occurence = new_word2num_occurence\n",
    "        self.idx2num_occurence = new_idx2num_occurence\n",
    "    def show(self):\n",
    "        for idx, word in enumerate(self.idx2word):\n",
    "            print(idx,'\\t', word,'\\t number of occurences = {}'.format(self.idx2num_occurence[idx]))\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "    \n",
    "# take a lists of smiles and use it to augment existing atom and bond dictionaries\n",
    "def augment_dictionary(atom_dict, bond_dict, list_of_smiles ):\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_dict.add_word( atom2symbol(atom) )\n",
    "        for bond in mol.GetBonds():\n",
    "            bond_dict.add_word( str(bond.GetBondType()) )\n",
    "\n",
    "# take three lists of smiles (train, val and test) and build atoms and bond dictionaries\n",
    "def make_dictionary(list_of_smiles_train, list_of_smiles_val, list_of_smiles_test):\n",
    "    atom_dict = Dictionary()\n",
    "    bond_dict = Dictionary()\n",
    "    bond_dict.add_word('NONE')\n",
    "    print('test..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_test )\n",
    "    print('val..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_val )  \n",
    "    print('train..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_train )\n",
    "    return atom_dict, bond_dict       \n",
    "\n",
    "# NOT independent of the property of aromaticity\n",
    "def contain_OOV_atom(smile, atom_dict ): \n",
    "    mybool = False\n",
    "    mol = Chem.MolFromSmiles(smile) \n",
    "    Chem.Kekulize(mol, clearAromaticFlags=True) # MUST remove aromatic bonds for OOV\n",
    "    for atom in mol.GetAtoms():\n",
    "        if atom2symbol(atom) not in atom_dict.word2idx:\n",
    "            mybool=True\n",
    "    return mybool\n",
    "\n",
    "# independent of having or not aromaticity\n",
    "def get_rid_of_OOV_smiles(list_of_smiles, atom_dict ):\n",
    "    new_list = []\n",
    "    OOV_list = []\n",
    "    for smiles in list_of_smiles:\n",
    "        if contain_OOV_atom(smiles, atom_dict ):\n",
    "            OOV_list.append(smiles)\n",
    "        else:\n",
    "            new_list.append(smiles)   \n",
    "    return new_list, OOV_list\n",
    "\n",
    "# logP\n",
    "def logP(mol):\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    return logp\n",
    "\n",
    "# SA  \n",
    "def SA(mol):\n",
    "    sa = sascorer.calculateScore(mol)\n",
    "    return sa\n",
    "\n",
    "# cycle\n",
    "def compute_cycle(smile):\n",
    "    cycle_list = nx.cycle_basis(nx.Graph(rdmolops.GetAdjacencyMatrix(Chem.MolFromSmiles(smile))))\n",
    "    if len(cycle_list) == 0:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = max([ len(j) for j in cycle_list ])\n",
    "    if cycle_length <= 6:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = cycle_length - 6\n",
    "    cycle_score = -cycle_length\n",
    "    return cycle_score\n",
    "\n",
    "def Cycle(mol):\n",
    "    smile = Chem.MolToSmiles(mol) # mol is supposed to be a valid rdkit molecule\n",
    "    cycle = float(compute_cycle(smile))\n",
    "    return cycle\n",
    "\n",
    "def logP_SA(mol):\n",
    "    logp = logP(mol)\n",
    "    sa = SA(mol)\n",
    "    return logp - sa\n",
    "\n",
    "def compute_stat_chem_prop_train_mol(smile_train):\n",
    "    logP_values = []\n",
    "    SA_values = []\n",
    "    cycle_values = []\n",
    "    for smile in smile_train: \n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        logP_values.append(logP(mol))\n",
    "        SA_values.append(-SA(mol))\n",
    "        cycle_values.append(Cycle(mol))\n",
    "    # stats\n",
    "    logP_values = torch.tensor(logP_values)\n",
    "    logP_values_mean = logP_values.mean().item()\n",
    "    logP_values_std = logP_values.std().item()\n",
    "    SA_values = torch.tensor(SA_values)\n",
    "    SA_values_mean = SA_values.mean().item()\n",
    "    SA_values_std = SA_values.std().item()\n",
    "    cycle_values = torch.tensor(cycle_values)\n",
    "    cycle_values_mean = cycle_values.mean().item()\n",
    "    cycle_values_std = cycle_values.std().item()\n",
    "    train_stat_mol_prop = [logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std]\n",
    "    return train_stat_mol_prop\n",
    "\n",
    "class Molecule:\n",
    "    \"\"\"\n",
    "    A molecule object contains the following attributes:\n",
    "        ; molecule.num_atom : nb of atoms, an integer (N)\n",
    "        ; molecule.atom_type : pytorch tensor of size N, each element is an atom type, an integer between 0 and num_atom_type-1\n",
    "        ; molecule.atom_type_pe : pytorch tensor of size N, each element is an atom type positional encoding, an integer between 0 and num_atom-1\n",
    "        ; molecule.bond_type : pytorch tensor of size N x N, each element is a bond type, an integer between 0 and num_bond_type-1 \n",
    "        ; molecule.bag_of_atoms : pytorch tensor of size num_atom_type, histogram of atoms in the molecule\n",
    "        ; molecule.logP_SA_cycle_normalized : the chemical property to regress, a pytorch float variable\n",
    "        ; molecule.smile : the smile representation of the molecule for rdkit, a string   \n",
    "    \"\"\"\n",
    "    def __init__(self, num_atom, num_atom_type):\n",
    "        self.num_atom       = num_atom\n",
    "        self.atom_type      = torch.zeros( num_atom , dtype=torch.long )\n",
    "        self.atom_type_pe   = torch.zeros( num_atom , dtype=torch.long )\n",
    "        self.bond_type      = torch.zeros( num_atom , num_atom, dtype=torch.long )\n",
    "        self.bag_of_atoms   = torch.zeros( num_atom_type, dtype=torch.long)\n",
    "        self.logP_SA        = torch.zeros( 1, dtype=torch.float)\n",
    "        self.logP_SA_cycle_normalized  = torch.zeros( 1, dtype=torch.float)\n",
    "        self.smile  = ''\n",
    "    def set_bag_of_atoms(self):\n",
    "        for tp in self.atom_type:\n",
    "                self.bag_of_atoms[tp.item()] += 1\n",
    "    def set_atom_type_pe(self):\n",
    "        histogram={}\n",
    "        for idx, tp in enumerate(self.atom_type):\n",
    "            tpp=tp.item()\n",
    "            if tpp not in histogram:\n",
    "                histogram[tpp] = 0\n",
    "            else:\n",
    "                histogram[tpp] += 1\n",
    "            self.atom_type_pe[idx] = histogram[tpp]\n",
    "    def shuffle_indexing(self):\n",
    "        idx = torch.randperm(self.num_atom)\n",
    "        self.atom_type = self.atom_type[idx]\n",
    "        self.atom_type_pe = self.atom_type_pe[idx]\n",
    "        self.bond_type = self.bond_type[idx][:,idx]\n",
    "        return idx\n",
    "    def __len__(self):\n",
    "        return self.num_atom\n",
    "    \n",
    "# convert smile molecule to pytorch molecule \n",
    "def from_smile_to_pymol(smile, atom_dict, bond_dict, stat_prop, remove_aromatic=False):\n",
    "    \"\"\"\n",
    "    This function take a smile an create a \"pytorch molecule\". \n",
    "    In order to do this we need to have some mapping between \n",
    "    type of atom and integers, and type of bonds an integer.\n",
    "    (see dictionary class below)\n",
    "\n",
    "    Input: a smile \n",
    "           a dictionary of atoms (that gives mapping of the type C --> 0, N --> 1, etc...)\n",
    "           a dictionary of bonds (that gives mapping of the type SINGLE --> 0,  AROMATIC --> 1, etc...)\n",
    "           \n",
    "    Output: return a pytorch molecule\n",
    "    \"\"\"\n",
    "    rdkit_mol = Chem.MolFromSmiles(smile)\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(rdkit_mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    N = rdkit_mol.GetNumAtoms()\n",
    "    num_atom_type = len(atom_dict)\n",
    "    pytorch_mol = Molecule(N,num_atom_type)   \n",
    "    # set the bond_type attribute\n",
    "    for bond in rdkit_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type_idx=bond_dict.word2idx[ str(bond.GetBondType()) ]\n",
    "        pytorch_mol.bond_type[i,j]= bond_type_idx\n",
    "        pytorch_mol.bond_type[j,i]= bond_type_idx      \n",
    "    # set the atom_type attribute\n",
    "    for atom in rdkit_mol.GetAtoms():\n",
    "        i=atom.GetIdx()\n",
    "        pytorch_mol.atom_type[i]=atom_dict.word2idx[ atom2symbol(atom) ]      \n",
    "    # set the atom_type_pe and bag of atoms attributes\n",
    "    pytorch_mol.set_bag_of_atoms() \n",
    "    pytorch_mol.set_atom_type_pe()\n",
    "    # set the target chemical property :  y(m) = logP(m) − SA(m) + cycle(m)\n",
    "    rdkit_mol = Chem.MolFromSmiles(smile) # do *not* remove aromatic bonds when logP_SA is computed \n",
    "    pytorch_mol.logP_SA = torch.Tensor([logP_SA(rdkit_mol)]) \n",
    "    logP_values_mean = stat_prop[0] \n",
    "    logP_values_std = stat_prop[1]\n",
    "    SA_values_mean = stat_prop[2]\n",
    "    SA_values_std = stat_prop[3]\n",
    "    cycle_values_mean = stat_prop[4]\n",
    "    cycle_values_std = stat_prop[5]\n",
    "    logP_value_normalized = (logP(rdkit_mol)-logP_values_mean)/logP_values_std\n",
    "    SA_value_normalized = (-SA(rdkit_mol)-SA_values_mean)/SA_values_std\n",
    "    cycle_value_normalized = (Cycle(rdkit_mol)-cycle_values_mean)/cycle_values_std\n",
    "    logP_SA_cycle_normalized = logP_value_normalized + SA_value_normalized + cycle_value_normalized\n",
    "    pytorch_mol.logP_SA_cycle_normalized = torch.Tensor([logP_SA_cycle_normalized])\n",
    "    pytorch_mol.smile = smile\n",
    "    return pytorch_mol\n",
    "\n",
    "def symbol2atom(aug_symb):\n",
    "    mylist=aug_symb.split()\n",
    "    atom = Chem.Atom(mylist[0])\n",
    "    if '+' in mylist:\n",
    "        atom.SetFormalCharge(1)\n",
    "    if '-' in mylist:\n",
    "        atom.SetFormalCharge(-1)\n",
    "    if 'H1' in mylist:\n",
    "        atom.SetNumExplicitHs(1)   \n",
    "    if 'H2' in mylist:\n",
    "        atom.SetNumExplicitHs(2)    \n",
    "    if 'H3' in mylist:\n",
    "        atom.SetNumExplicitHs(3)\n",
    "    return atom\n",
    "\n",
    "def from_mol_to_smile(mol, remove_aromatic=False):\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    smile = Chem.MolToSmiles(mol)\n",
    "    return smile\n",
    "\n",
    "def from_pymol_to_smile(pymol, atom_dict, bond_dict, remove_aromatic=False):\n",
    "    N = pymol.num_atom \n",
    "    mol = Chem.RWMol()\n",
    "    for tp in pymol.atom_type:\n",
    "        symbol = atom_dict.idx2word[ tp.item() ]\n",
    "        mol.AddAtom( symbol2atom(symbol) )\n",
    "    for i in range(0,N): \n",
    "        for j in range(i+1,N): \n",
    "            tp = pymol.bond_type[i,j].item()\n",
    "            bond_stg = bond_dict.idx2word[tp]\n",
    "            if bond_stg!='NONE':\n",
    "                if bond_stg=='SINGLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.SINGLE)\n",
    "                if bond_stg=='DOUBLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.DOUBLE)\n",
    "                if bond_stg=='TRIPLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.TRIPLE)\n",
    "                if bond_stg=='AROMATIC':\n",
    "                    #print('ISSUE: MUST BE NO AROMATIC BONDS !!!!')\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.AROMATIC)\n",
    "    smile = from_mol_to_smile(mol,remove_aromatic)\n",
    "    return smile\n",
    "\n",
    "def rm_stereo(smile, remove_aromatic=False):\n",
    "    smile = smile.replace('\\\\' , \"\")\n",
    "    smile = smile.replace(\"/\", \"\") \n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    smile = Chem.MolToSmiles(mol, isomericSmiles=False) # remove stereo\n",
    "    return smile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pytorch datasets from original smile datasets \n",
    "Note: I do not use the full datasets for the course, only a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert csv files to panda dataframes\n",
      "                  smiles\n",
      "0  N[C]1[N]C2CC1[N][C]2N\n",
      "1            CCn1cncc1OC\n",
      "2          OC1CCCCC(O)C1\n",
      "3         CCC1C2OCC12C=O\n",
      "4       CN1C(=O)CN=C1C=O\n",
      "Extract subsets of datasets\n",
      "                  smiles\n",
      "0  N[C]1[N]C2CC1[N][C]2N\n",
      "1            CCn1cncc1OC\n",
      "2          OC1CCCCC(O)C1\n",
      "3         CCC1C2OCC12C=O\n",
      "4       CN1C(=O)CN=C1C=O\n",
      "Convert the panda data frame into a list of smiles\n",
      "['N[C]1[N]C2CC1[N][C]2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "clean QM9 smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "remove stereo symbols in smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Change original smiles to rdkit-smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Remove aromatic bonds\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Building atom and bond dictionaries..\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "0 \t N \t number of occurences = 1419\n",
      "1 \t C \t number of occurences = 8904\n",
      "2 \t O \t number of occurences = 1922\n",
      "3 \t F \t number of occurences = 48\n",
      "4 \t N H3 + \t number of occurences = 2\n",
      "5 \t O - \t number of occurences = 2\n",
      "6 \t C H1 - \t number of occurences = 1\n",
      "7 \t N + \t number of occurences = 1\n",
      "8 \t N - \t number of occurences = 1\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "Get rid of rare coumpounds and only keep the following\n",
      "0 \t N \t number of occurences = 1419\n",
      "1 \t C \t number of occurences = 8904\n",
      "2 \t O \t number of occurences = 1922\n",
      "3 \t F \t number of occurences = 48\n",
      "4 \t N H3 + \t number of occurences = 2\n",
      "5 \t O - \t number of occurences = 2\n",
      "6 \t C H1 - \t number of occurences = 1\n",
      "7 \t N + \t number of occurences = 1\n",
      "8 \t N - \t number of occurences = 1\n",
      "Get rid of OOV smiles..\n",
      "test set size : \t 200 (0 were discarded)\n",
      "val set size : \t 200 (0 were discarded)\n",
      "train set size : \t 1000 (0 were discarded)\n",
      "Compute statistical chemical properties of train molecules\n",
      "logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std:\n",
      " [0.32592248916625977, 0.97919100522995, -4.237425804138184, 0.9593134522438049, -0.03999999910593033, 0.2246117740869522]\n",
      "Convert smiles to pytorch molecules...\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 2, 3, 2, 4, 3])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([4, 5, 0, 0, 0, 0, 0, 0, 0])\n",
      "NC1NC2CC1NC2N\n",
      "logP_SA tensor([-8.3573])\n",
      "logP_SA_cycle_normalized tensor([-4.4048])\n",
      "smile_test NC1NC2CC1NC2N\n",
      "Sanity check: convert pytorch molecules back to smiles and check we recover the original smiles\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "percentage of correct smiles --> pytorch molecules --> smiles: test/val/train 100.0%/100.0%/100.0%\n",
      "Saving pytorch molecules to folder : QM9_pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: QM9_pytorch: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 5.929295063018799\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "# folders\n",
    "data_folder_smile = 'QM9_smile'\n",
    "data_folder_pytorch = 'QM9_pytorch' \n",
    "# data_folder_smile = 'ZINC_smile'\n",
    "# data_folder_pytorch = 'ZINC_pytorch' \n",
    "\n",
    "print('Convert csv files to panda dataframes')\n",
    "df_train = pd.read_csv(data_folder_smile + '/train_smile.txt')\n",
    "df_val = pd.read_csv(data_folder_smile +'/valid_smile.txt')\n",
    "df_test = pd.read_csv(data_folder_smile + '/test_smile.txt')\n",
    "# df_train = pd.read_csv(data_folder_smile + '/test_smile.txt') # DEBUG !\n",
    "# df_val = pd.read_csv(data_folder_smile +'/test_smile.txt')   # DEBUG !\n",
    "# df_test = pd.read_csv(data_folder_smile + '/test_smile.txt')  # DEBUG !\n",
    "print(df_test[:5])\n",
    "\n",
    "print('Extract subsets of datasets') # comment the following lines to use full datasets <==========\n",
    "                                     # Subsets are for teaching purpose\n",
    "df_train = df_train[:1000] # truncated dataset !\n",
    "df_val = df_val[:200]      # truncated dataset !\n",
    "df_test = df_test[:200]    # truncated dataset !\n",
    "print(df_test[:5])\n",
    "\n",
    "print('Convert the panda data frame into a list of smiles')\n",
    "smile_train = [ df_train.loc[i,'smiles'] for i in df_train.index  ]\n",
    "smile_val   = [ df_val.loc[i,'smiles']   for i in df_val.index    ]\n",
    "smile_test  = [ df_test.loc[i,'smiles']  for i in df_test.index   ]\n",
    "print(smile_test[:5])\n",
    "\n",
    "# Change QM9 smiles : [C]=>C, [N]=>N, [O]=>O, [CH]=>C, [NH]=>N\n",
    "print('clean QM9 smiles')\n",
    "smile_train = clean_qm9_smiles(smile_train)\n",
    "smile_val = clean_qm9_smiles(smile_val)\n",
    "smile_test = clean_qm9_smiles(smile_test) \n",
    "print(smile_test[:5]) \n",
    "\n",
    "# Clean stereo smiles\n",
    "print('remove stereo symbols in smiles')\n",
    "smile_train = remove_stereo_smiles(smile_train)\n",
    "smile_val = remove_stereo_smiles(smile_val)\n",
    "smile_test = remove_stereo_smiles(smile_test)   \n",
    "print(smile_test[:5]) \n",
    "\n",
    "print('Change original smiles to rdkit-smiles')\n",
    "smile_train = [ from_smile_to_rdkit_smile(smile) for smile in smile_train ]\n",
    "smile_val =   [ from_smile_to_rdkit_smile(smile) for smile in smile_val ]\n",
    "smile_test =  [ from_smile_to_rdkit_smile(smile) for smile in smile_test ]\n",
    "print(smile_test[:5]) \n",
    "\n",
    "print('Remove aromatic bonds')\n",
    "smile_train = remove_aromatic_bonds(smile_train)\n",
    "smile_val = remove_aromatic_bonds(smile_val)\n",
    "smile_test = remove_aromatic_bonds(smile_test)\n",
    "print(smile_test[:5]) \n",
    "\n",
    "# Use the lists of smiles to build dictionaries of atoms and bonds\n",
    "print('Building atom and bond dictionaries..')\n",
    "atom_dict, bond_dict = make_dictionary(smile_train, smile_val, smile_test)\n",
    "atom_dict.show()\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "# Trim dataset\n",
    "print('Get rid of rare coumpounds and only keep the following') \n",
    "#atom_dict.get_rid_of_rare_words(100) # if this line is commented then all coumpounds are kept\n",
    "                                      # comment out for getting rid of rare coumpounds with threshold frequency\n",
    "atom_dict.show()\n",
    "\n",
    "print('Get rid of OOV smiles..')\n",
    "smile_test,  OOV_smile_test  = get_rid_of_OOV_smiles( smile_test,  atom_dict )\n",
    "print('test set size : \\t {} ({} were discarded)'.format( len(smile_test) ,  len(OOV_smile_test)) )\n",
    "smile_val,   OOV_smile_val   = get_rid_of_OOV_smiles( smile_val,   atom_dict )\n",
    "print('val set size : \\t {} ({} were discarded)'.format( len(smile_val) ,  len(OOV_smile_val)) )\n",
    "smile_train, OOV_smile_train = get_rid_of_OOV_smiles( smile_train, atom_dict )\n",
    "print('train set size : \\t {} ({} were discarded)'.format( len(smile_train) ,  len(OOV_smile_train)) )\n",
    "        \n",
    "# Compute chemical properties of train molecules (logP, SA, cycle)  \n",
    "print('Compute statistical chemical properties of train molecules')\n",
    "train_stat_mol_prop = compute_stat_chem_prop_train_mol(smile_train)\n",
    "print('logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std:\\n',train_stat_mol_prop)\n",
    "\n",
    "# Convert the lists of smiles into lists of pytorch molecules\n",
    "print('Convert smiles to pytorch molecules...')\n",
    "stat = train_stat_mol_prop\n",
    "print('test..')\n",
    "test  = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_test  ]\n",
    "#test  = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_test  ]\n",
    "print('val..')\n",
    "val   = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_val   ]\n",
    "#val   = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_val   ]\n",
    "print('train..')\n",
    "train = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_train ]\n",
    "#train = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_train ]\n",
    "print(test[0].atom_type)\n",
    "print(test[0].atom_type_pe)\n",
    "print(test[0].bond_type)\n",
    "print(test[0].bag_of_atoms)\n",
    "print(test[0].smile)\n",
    "# properties given molecules : \n",
    "# logP : water-octanal partition coefficient\n",
    "# SA : synthetic accessibility score\n",
    "# QED : Qualitative Estimate of Drug-likeness\n",
    "# logP_SA = logP − SA\n",
    "print('logP_SA',test[0].logP_SA)\n",
    "print('logP_SA_cycle_normalized',test[0].logP_SA_cycle_normalized)\n",
    "print('smile_test',smile_test[0])\n",
    "\n",
    "# Sanity check : smile => pytorch => smile\n",
    "print('Sanity check: convert pytorch molecules back to smiles and check we recover the original smiles')\n",
    "print('test..')\n",
    "smile_test2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in test  ]\n",
    "print('val..')\n",
    "smile_val2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in val  ]\n",
    "print('train..')\n",
    "smile_train2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in train  ]\n",
    "print(smile_test[:5]) \n",
    "print(smile_test2[:5]) \n",
    "def accuracy_btw_smiles(smiles_list1, smiles_list2):\n",
    "    count=0\n",
    "    for idx,sm in enumerate(smiles_list1):\n",
    "        if rm_stereo(sm,True) == smiles_list2[idx]:\n",
    "            count+=1\n",
    "            #print('idx:',idx,' Smile:',rm_stereo(sm),' Smile=>mol=>smile:',smiles_list2[idx])\n",
    "        else:\n",
    "            #print('')\n",
    "            print('idx:',idx,' Smile:',rm_stereo(sm),' Smile=>mol=>smile:',smiles_list2[idx])\n",
    "    return count/len(smiles_list1)\n",
    "acc_test = accuracy_btw_smiles(smile_test, smile_test2)\n",
    "acc_val = accuracy_btw_smiles(smile_val, smile_val2)\n",
    "acc_train = accuracy_btw_smiles(smile_train, smile_train2)\n",
    "print('percentage of correct smiles --> pytorch molecules --> smiles: test/val/train {}%/{}%/{}%'.format(\n",
    "    acc_test*100, acc_val*100, acc_train*100))\n",
    "\n",
    "# Saving\n",
    "print('Saving pytorch molecules to folder : ' + data_folder_pytorch )\n",
    "os.system(\"mkdir \" + data_folder_pytorch )\n",
    "with open(data_folder_pytorch + \"/atom_dict.pkl\",\"wb\") as f:\n",
    "    pickle.dump(atom_dict,f)\n",
    "with open(data_folder_pytorch + \"/bond_dict.pkl\",\"wb\") as f:\n",
    "    pickle.dump(bond_dict, f)\n",
    "with open(data_folder_pytorch + \"/test_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(test,f)\n",
    "with open(data_folder_pytorch +  \"/val_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(val,f)\n",
    "with open(data_folder_pytorch +  \"/train_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(train,f)\n",
    "print('Time:',time.time()-start)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pytorch molecule and visualize with rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN1C(=O)CN=C1C=O\n",
      "tensor([1, 0, 1, 2, 1, 0, 1, 1, 2])\n",
      "tensor([0, 0, 1, 0, 2, 1, 3, 4, 1])\n",
      "9\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 2, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 2, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 2, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 2],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 2, 0]])\n",
      "tensor([2, 5, 2, 0, 0, 0, 0, 0, 0])\n",
      "tensor([-0.4965])\n",
      "CN1C(=O)CN=C1C=O\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x32989a190>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4\n",
    "\n",
    "print(test[idx].smile)\n",
    "print(test[idx].atom_type)\n",
    "print(test[idx].atom_type_pe)\n",
    "print(test[idx].num_atom)\n",
    "print(test[idx].bond_type)\n",
    "print(test[idx].bag_of_atoms)\n",
    "print(test[idx].logP_SA_cycle_normalized)\n",
    "print(test[idx].smile)\n",
    "\n",
    "mol = Chem.MolFromSmiles(test[idx].smile)\n",
    "mol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "QM9_pytorch/\n",
      "Time: 1.1002569198608398\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "9 4\n",
      "tensor([1, 1, 2, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 2, 3, 4, 5])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([0, 6, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1.5997])\n",
      "CC(O)C1CC1C\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "start = time.time()\n",
    "\n",
    "data_folder_pytorch = 'QM9_pytorch/'\n",
    "# data_folder_pytorch = 'ZINC_pytorch/'\n",
    "print(data_folder_pytorch)\n",
    "\n",
    "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
    "    atom_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
    "    bond_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"test_pytorch.pkl\",\"rb\") as f:\n",
    "    test=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"val_pytorch.pkl\",\"rb\") as f:\n",
    "    val=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"train_pytorch.pkl\",\"rb\") as f:\n",
    "    train=pickle.load(f)\n",
    "print('Time:',time.time()-start)\n",
    "\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "num_atom_type = len(atom_dict.idx2word)\n",
    "num_bond_type = len(bond_dict.idx2word)\n",
    "print(num_atom_type, num_bond_type)\n",
    "\n",
    "idx = 45\n",
    "print(train[idx].atom_type)\n",
    "print(train[idx].atom_type_pe)\n",
    "print(train[idx].bond_type)\n",
    "print(train[idx].bag_of_atoms)\n",
    "print(train[idx].logP_SA_cycle_normalized)\n",
    "print(train[idx].smile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing molecules per size...\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "# Organize data into group of of molecules of fixed sized\n",
    "# For example, train is a dictionary\n",
    "# And train[22] is a list containing all the molecules of size 22  \n",
    "print(\"Organizing molecules per size...\")\n",
    "\n",
    "def group_molecules_per_size(dataset):\n",
    "    mydict={}\n",
    "    for mol in dataset:\n",
    "        if len(mol) not in mydict:\n",
    "            mydict[len(mol)]=[]\n",
    "        mydict[len(mol)].append(mol)\n",
    "    return mydict\n",
    "\n",
    "test_group  = group_molecules_per_size(test)\n",
    "val_group   = group_molecules_per_size(val)\n",
    "train_group = group_molecules_per_size(train)\n",
    "print(len(train_group[8])) # QM9\n",
    "# print(len(train_group[28])) # ZINC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max num atoms =  9\n"
     ]
    }
   ],
   "source": [
    "# what is the biggest molecule in the train set\n",
    "max_mol_sz= max(list( train_group.keys()))\n",
    "print('Max num atoms = ', max_mol_sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "number of molecule of size 4: \t 1\n",
      "number of molecule of size 5: \t 1\n",
      "number of molecule of size 6: \t 7\n",
      "number of molecule of size 7: \t 24\n",
      "number of molecule of size 8: \t 136\n",
      "number of molecule of size 9: \t 831\n",
      "Val\n",
      "number of molecule of size 7: \t 6\n",
      "number of molecule of size 8: \t 28\n",
      "number of molecule of size 9: \t 166\n",
      "Test\n",
      "number of molecule of size 6: \t 1\n",
      "number of molecule of size 7: \t 3\n",
      "number of molecule of size 8: \t 37\n",
      "number of molecule of size 9: \t 159\n"
     ]
    }
   ],
   "source": [
    "# distribution w.r.t. molecule size\n",
    "print('Train')\n",
    "data = train_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "print('Val')\n",
    "data = val_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "print('Test')\n",
    "data = test_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate batch of pytorch molecules of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to help drawing batches of molecules having the same size\n",
    "class MoleculeSampler:\n",
    "    \"\"\"\n",
    "    The dataset is a dictionary where the keys are the molecule sizes, and\n",
    "    the values are lists of pytorch molecule of the given size.\n",
    "    The MoleculeSampler will choose a size at random, and then provide the bs indices\n",
    "    of the molecules of this size to be drawn.\n",
    "\n",
    "    ATTRIBUTE:\n",
    "\n",
    "    bs: batch size\n",
    "\n",
    "    num_mol: (dictionary) key = size \n",
    "                          value = number of molecules of this size\n",
    "\n",
    "    counter: (dictionary) key   = size\n",
    "                          value = number of molecules of this size that have already been processed\n",
    "\n",
    "    order:   (dictionary) key = size\n",
    "                                value= np-array describing in which order \n",
    "                                       the molecules of this given size are going to be vistited                         \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, organized_dataset, bs , shuffle=True):  \n",
    "        self.bs=bs\n",
    "        self.num_mol =  { sz: len(list_of_mol)  for sz , list_of_mol in organized_dataset.items() }\n",
    "        self.counter = { sz: 0   for sz in organized_dataset }\n",
    "        if shuffle:\n",
    "            self.order = { sz: np.random.permutation(num)  for sz , num in self.num_mol.items() }\n",
    "        else:\n",
    "            self.order = { sz: np.arange(num)  for sz , num in self.num_mol.items() } \n",
    "\n",
    "\n",
    "    def compute_num_batches_remaining(self):\n",
    "        return {sz:  ( self.num_mol[sz] - self.counter[sz] ) // self.bs  for sz in self.num_mol}\n",
    "\n",
    "    def choose_molecule_size(self):\n",
    "        num_batches= self.compute_num_batches_remaining()\n",
    "        possible_sizes =  np.array( list( num_batches.keys()) )\n",
    "        prob           =  np.array( list( num_batches.values() )   ) \n",
    "        prob =  prob / prob.sum()\n",
    "        sz   = np.random.choice(  possible_sizes , p=prob )\n",
    "        return sz\n",
    "\n",
    "    def is_empty(self):\n",
    "        num_batches= self.compute_num_batches_remaining()\n",
    "        return sum( num_batches.values() ) == 0\n",
    "\n",
    "    def draw_batch_of_molecules(self,sz):  \n",
    "        indices=self.order[sz][ self.counter[sz] : self.counter[sz] + self.bs]\n",
    "        self.counter[sz] += self.bs  \n",
    "        return indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[610 499 123  15 702 107 462 719 227 666 563 456 592  41 755 637  50 100\n",
      " 262 174  47  49 394 753 275 699 429 421 712  43 786 207 730 691 817 521\n",
      " 544 302 110 454 503 655 412 215 308 331 794 132 645 560]\n",
      "torch.Size([50, 9])\n",
      "torch.Size([50, 9])\n",
      "torch.Size([50, 9, 9])\n",
      "torch.Size([50, 9])\n",
      "torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "sampler = MoleculeSampler(train_group, bs)\n",
    "\n",
    "# get a batch\n",
    "sz = sampler.choose_molecule_size()\n",
    "print(sz)\n",
    "indices = sampler.draw_batch_of_molecules(sz) \n",
    "print(indices)\n",
    "minibatch_node = torch.stack( [ train_group[sz][i].atom_type for i in indices] )\n",
    "print(minibatch_node.size())\n",
    "minibatch_pe  = torch.stack( [ train_group[sz][i].atom_type_pe  for i in indices] )\n",
    "print(minibatch_pe.size())\n",
    "minibatch_edge = torch.stack( [ train_group[sz][i].bond_type for i in indices] )\n",
    "print(minibatch_edge.size())\n",
    "minibatch_boa = torch.stack( [ train_group[sz][i].bag_of_atoms for i in indices] )\n",
    "print(minibatch_boa.size())\n",
    "minibatch_logP_SA_cycle_normalized = torch.stack( [ train_group[sz][i].logP_SA_cycle_normalized for i in indices] )\n",
    "print(minibatch_logP_SA_cycle_normalized.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-loading pytorch molecules (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "QM9_pytorch/\n",
      "Time: 0.29868388175964355\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "9 4\n",
      "tensor([1, 1, 2, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 2, 3, 4, 5])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([0, 6, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1.5997])\n",
      "CC(O)C1CC1C\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "start=time.time()\n",
    "\n",
    "data_folder_pytorch = 'QM9_pytorch/'\n",
    "# data_folder_pytorch = 'ZINC_pytorch/'\n",
    "print(data_folder_pytorch)\n",
    "\n",
    "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
    "    atom_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
    "    bond_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"test_pytorch.pkl\",\"rb\") as f:\n",
    "    test=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"val_pytorch.pkl\",\"rb\") as f:\n",
    "    val=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"train_pytorch.pkl\",\"rb\") as f:\n",
    "    train=pickle.load(f)\n",
    "print('Time:',time.time()-start)\n",
    "\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "num_atom_type = len(atom_dict.idx2word)\n",
    "num_bond_type = len(bond_dict.idx2word)\n",
    "print(num_atom_type, num_bond_type)\n",
    "\n",
    "idx = 45\n",
    "print(train[idx].atom_type)\n",
    "print(train[idx].atom_type_pe)\n",
    "print(train[idx].bond_type)\n",
    "print(train[idx].bag_of_atoms)\n",
    "print(train[idx].logP_SA_cycle_normalized)\n",
    "print(train[idx].smile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions to generate DGL molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, split):\n",
    "        self.split = split\n",
    "        with open(data_dir + \"/%s_pytorch.pkl\" % split,\"rb\") as f:\n",
    "            self.data = pickle.load(f)\n",
    "        num_graphs = len(self.data)\n",
    "        self.graph_lists = []\n",
    "        self.graph_labels = []\n",
    "        self.num_graphs = num_graphs\n",
    "        self._prepare()\n",
    "    def _prepare(self):\n",
    "        print(\"preparing %d graphs for the %s set...\" % (self.num_graphs, self.split.upper()))\n",
    "        for molecule in self.data:\n",
    "            node_features = molecule.atom_type.long()\n",
    "            adj = molecule.bond_type\n",
    "            edge_list = (adj != 0).nonzero() # converting adj matrix to edge_list\n",
    "            edge_idxs_in_adj = edge_list.split(1, dim=1)\n",
    "            edge_features = adj[edge_idxs_in_adj].reshape(-1).long()\n",
    "            # version 2020 -- tmp\n",
    "            #g = dgl.DGLGraph() # create the DGL graph\n",
    "            #g.add_nodes(molecule.num_atom)\n",
    "            #for src, dst in edge_list:\n",
    "            #    g.add_edges(src.item(), dst.item())  \n",
    "            # version 2023\n",
    "            g = dgl.graph((edge_list[:,0], edge_list[:,1]), num_nodes=molecule.num_atom) # create the DGL graph  \n",
    "            g.ndata['feat'] = node_features\n",
    "            g.edata['feat'] = edge_features\n",
    "            self.graph_lists.append(g)\n",
    "            self.graph_labels.append(molecule.logP_SA_cycle_normalized)\n",
    "    def __len__(self):\n",
    "        return self.num_graphs\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_lists[idx], self.graph_labels[idx]\n",
    "    \n",
    "class MoleculeDatasetDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_name, data_dir):\n",
    "        t0 = time.time()\n",
    "        print('dataset: %s' % data_name)\n",
    "        with open(data_dir + \"/atom_dict.pkl\" ,\"rb\") as f: atom_dict = pickle.load(f)\n",
    "        with open(data_dir + \"/bond_dict.pkl\" ,\"rb\") as f: bond_dict = pickle.load(f)\n",
    "        self.num_atom_type = len(atom_dict)\n",
    "        self.num_bond_type = len(bond_dict)\n",
    "        self.train = MoleculeDGL(data_dir, 'train')\n",
    "        self.val   = MoleculeDGL(data_dir, 'val')\n",
    "        self.test  = MoleculeDGL(data_dir, 'test')\n",
    "        print(\"Time taken: {:.4f}s\".format(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DGL datasets from pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: QM9\n",
      "preparing 1000 graphs for the TRAIN set...\n",
      "preparing 200 graphs for the VAL set...\n",
      "preparing 200 graphs for the TEST set...\n",
      "Time taken: 0.9896s\n",
      "1000\n",
      "200\n",
      "200\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-0.2532]))\n",
      "(Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.5060]))\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-4.4048]))\n",
      "Saving dgl molecules to folder : QM9_dgl/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: QM9_dgl/: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.3792569637298584\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "# Convert pytorch to dgl format\n",
    "dataset_name = 'QM9'\n",
    "# dataset_name = 'ZINC'\n",
    "dataset = MoleculeDatasetDGL(dataset_name, data_folder_pytorch) \n",
    "\n",
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "idx = 0\n",
    "print(dataset.train[idx])\n",
    "print(dataset.val[idx])\n",
    "print(dataset.test[idx])\n",
    "\n",
    "# Saving\n",
    "data_folder_dgl = 'QM9_dgl/'\n",
    "# data_folder_dgl = 'ZINC_dgl/'\n",
    "print('Saving dgl molecules to folder : ' + data_folder_dgl )\n",
    "os.system(\"mkdir \" + data_folder_dgl )\n",
    "with open(data_folder_dgl + \"/test_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.test,f)\n",
    "with open(data_folder_dgl +  \"/val_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.val,f)\n",
    "with open(data_folder_dgl +  \"/train_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.train,f)\n",
    "print('Time:',time.time()-start)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility class for loading DGL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_name, data_dir):\n",
    "        start = time.time()\n",
    "        print(\"Loading datasets %s_dgl...\" % (data_name))\n",
    "        with open(data_dir + 'train_dgl.pkl',\"rb\") as f:\n",
    "            self.train = pickle.load(f)\n",
    "        with open(data_dir + 'val_dgl.pkl',\"rb\") as f:\n",
    "            self.val = pickle.load(f)\n",
    "        with open(data_dir + 'test_dgl.pkl',\"rb\") as f:\n",
    "            self.test = pickle.load(f)\n",
    "        print('train, test, val sizes :',len(self.train),len(self.test),len(self.val))\n",
    "        print(\"Time: {:.4f}s\".format(time.time()-start))\n",
    "    # form a mini batch from a given list of samples = [(graph, label) pairs]\n",
    "    # collate requires a method __getitem__ in the graph class used\n",
    "    def collate(self, samples):\n",
    "        # Input sample is a list of pairs (graph, label)\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        batch_graphs = dgl.batch(graphs)\n",
    "        batch_labels = torch.stack(labels)\n",
    "        # Normalization w.r.t. graph sizes\n",
    "        tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        tab_norm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        batch_norm_n = torch.cat(tab_norm_n).sqrt()  \n",
    "        tab_sizes_e = [ graphs[i].number_of_edges() for i in range(len(graphs))]\n",
    "        tab_norm_e = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_e ]\n",
    "        batch_norm_e = torch.cat(tab_norm_e).sqrt()\n",
    "        return batch_graphs, batch_labels, batch_norm_n, batch_norm_e\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DGL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "4\n",
      "Loading datasets QM9_dgl...\n",
      "train, test, val sizes : 1000 200 200\n",
      "Time: 0.9693s\n",
      "1000\n",
      "200\n",
      "200\n",
      "([Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)})], [tensor([-0.2532]), tensor([1.0897])])\n",
      "(Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.5060]))\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-4.4048]))\n"
     ]
    }
   ],
   "source": [
    "# Load the number of atom and bond types \n",
    "with open(data_folder_pytorch + \"/atom_dict.pkl\" ,\"rb\") as f: num_atom_type = len(pickle.load(f))\n",
    "with open(data_folder_pytorch + \"/bond_dict.pkl\" ,\"rb\") as f: num_bond_type = len(pickle.load(f))\n",
    "print(num_atom_type)\n",
    "print(num_bond_type)\n",
    "\n",
    "# Load the DGL datasets\n",
    "dataset_name = 'QM9'\n",
    "# dataset_name = 'ZINC'\n",
    "datasets_dgl = MoleculeDataset(dataset_name, data_folder_dgl)\n",
    "trainset, valset, testset = datasets_dgl.train, datasets_dgl.val, datasets_dgl.test\n",
    "\n",
    "print(len(trainset))\n",
    "print(len(valset))\n",
    "print(len(testset))\n",
    "\n",
    "idx = 0\n",
    "print(trainset[:2])\n",
    "print(valset[idx])\n",
    "print(testset[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate batch of graphs (of different sizes) with DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=879, num_edges=1880,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)})\n",
      "tensor([[ 8.6624e-01],\n",
      "        [-3.3447e+00],\n",
      "        [-6.0830e-02],\n",
      "        [ 3.3920e+00],\n",
      "        [-3.6141e+00],\n",
      "        [ 7.4368e-01],\n",
      "        [-4.0181e+00],\n",
      "        [-2.7663e-02],\n",
      "        [-2.0127e+00],\n",
      "        [ 4.2416e-01],\n",
      "        [ 2.5597e-01],\n",
      "        [ 1.6995e-01],\n",
      "        [-2.2021e+00],\n",
      "        [-5.3127e-01],\n",
      "        [ 2.8163e+00],\n",
      "        [ 2.1653e+00],\n",
      "        [-4.6346e-01],\n",
      "        [ 1.2764e+00],\n",
      "        [-1.2300e+00],\n",
      "        [-9.0810e-03],\n",
      "        [ 3.2543e-01],\n",
      "        [ 1.7773e+00],\n",
      "        [ 6.4179e-01],\n",
      "        [ 2.7188e+00],\n",
      "        [-1.0064e+00],\n",
      "        [ 5.8335e-01],\n",
      "        [ 9.0248e-01],\n",
      "        [-8.4047e-01],\n",
      "        [-3.2582e+00],\n",
      "        [ 1.4905e+00],\n",
      "        [ 3.5735e-01],\n",
      "        [ 1.7684e+00],\n",
      "        [-6.7292e-01],\n",
      "        [-1.6318e-01],\n",
      "        [ 8.2086e-01],\n",
      "        [ 7.1339e-01],\n",
      "        [-2.2726e+00],\n",
      "        [ 5.8500e-01],\n",
      "        [-1.4193e+00],\n",
      "        [-1.0406e+00],\n",
      "        [ 4.7726e-01],\n",
      "        [-1.1561e+00],\n",
      "        [-5.4186e-02],\n",
      "        [-6.2248e+00],\n",
      "        [-2.0343e+00],\n",
      "        [ 7.8003e-01],\n",
      "        [ 6.0215e-02],\n",
      "        [-9.5165e-01],\n",
      "        [ 7.5569e-01],\n",
      "        [ 5.4020e-01],\n",
      "        [ 1.3955e+00],\n",
      "        [ 1.2856e-01],\n",
      "        [-1.1892e+00],\n",
      "        [ 1.2511e+00],\n",
      "        [-2.5573e-01],\n",
      "        [-1.1119e+00],\n",
      "        [ 3.5677e-01],\n",
      "        [ 4.1770e-01],\n",
      "        [ 1.6270e-03],\n",
      "        [ 1.3169e+00],\n",
      "        [-2.1486e+00],\n",
      "        [-7.1734e-01],\n",
      "        [-2.2021e+00],\n",
      "        [ 2.0209e+00],\n",
      "        [-3.5125e+00],\n",
      "        [ 4.5592e+00],\n",
      "        [-9.5793e-01],\n",
      "        [-5.3283e-01],\n",
      "        [ 3.6165e+00],\n",
      "        [-3.0772e+00],\n",
      "        [-1.6490e+00],\n",
      "        [ 8.5694e-01],\n",
      "        [ 5.1267e-01],\n",
      "        [-1.0809e+00],\n",
      "        [ 1.7118e+00],\n",
      "        [-6.4951e-01],\n",
      "        [ 1.6861e+00],\n",
      "        [ 4.9066e-01],\n",
      "        [-4.0222e+00],\n",
      "        [ 1.2445e-01],\n",
      "        [ 1.2354e+00],\n",
      "        [ 2.0619e+00],\n",
      "        [ 2.4068e+00],\n",
      "        [-4.4240e+00],\n",
      "        [ 2.5154e+00],\n",
      "        [ 7.9624e-02],\n",
      "        [-2.1641e+00],\n",
      "        [ 8.3712e-02],\n",
      "        [-1.9563e-01],\n",
      "        [-4.2115e-01],\n",
      "        [ 3.0240e+00],\n",
      "        [ 1.1648e+00],\n",
      "        [ 9.8523e-01],\n",
      "        [-3.8988e+00],\n",
      "        [-1.7892e+00],\n",
      "        [ 6.6915e-01],\n",
      "        [-3.0417e+00],\n",
      "        [ 9.1774e-01],\n",
      "        [-2.5990e-01],\n",
      "        [ 2.4087e+00]])\n",
      "torch.Size([879, 1])\n",
      "torch.Size([1880, 1])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "batch_x torch.Size([881])\n",
      "batch_e torch.Size([1908])\n",
      "batch_norm_n torch.Size([881, 1])\n",
      "batch_norm_e torch.Size([1908, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=datasets_dgl.collate)\n",
    "\n",
    "batch_graphs, batch_labels, batch_norm_n, batch_norm_e = list(train_loader)[0]\n",
    "print(batch_graphs)\n",
    "print(batch_labels)\n",
    "print(batch_norm_n.size())\n",
    "print(batch_norm_e.size())\n",
    "\n",
    "for iter, (batch_graphs, batch_labels, batch_norm_n, batch_norm_e) in enumerate(train_loader):\n",
    "    print(iter)\n",
    "    \n",
    "batch_x = batch_graphs.ndata['feat']\n",
    "print('batch_x',batch_x.size())\n",
    "batch_e = batch_graphs.edata['feat']\n",
    "print('batch_e',batch_e.size())\n",
    "print('batch_norm_n',batch_norm_n.size())\n",
    "print('batch_norm_e',batch_norm_e.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
